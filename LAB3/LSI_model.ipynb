{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b594cce",
   "metadata": {},
   "source": [
    "## Expected Steps for LSI model\n",
    "- Build the TF‚ÄìIDF Matrix ùëä\n",
    "- Apply Singular Value Decomposition (SVD), using the numpy decomposition\n",
    "function\n",
    "\n",
    "      U, S, VT = np.linalg.svd(W, full_matrices=False)\n",
    "- Reduce Dimensionality to K=3\n",
    "- Represent the queries as binary vectors (1 if term exists 0 else)\n",
    "- Project them into the new latent semantic space dimensions using the formula given\n",
    "in the lecture notes\n",
    "- Compute similarity between the queries and all documents, using the formula given\n",
    "in the lecture notes\n",
    "- Rank the Documents for each query in decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def5097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF‚ÄìIDF Matrix W:\n",
      "             D1        D2        D3      D4        D5        D6\n",
      "1      0.000000  0.000000  0.000000  0.0000  0.000000  0.105637\n",
      "10%    0.000000  0.281699  0.000000  0.0000  0.000000  0.000000\n",
      "12%    0.000000  0.000000  0.000000  0.0939  0.000000  0.000000\n",
      "175    0.000000  0.140850  0.000000  0.0000  0.000000  0.000000\n",
      "18%    0.169020  0.000000  0.000000  0.0000  0.000000  0.000000\n",
      "...         ...       ...       ...     ...       ...       ...\n",
      "word   0.000000  0.000000  0.150515  0.0000  0.100343  0.000000\n",
      "world  0.000000  0.000000  0.105637  0.0000  0.000000  0.000000\n",
      "x      0.000000  0.140850  0.000000  0.0000  0.000000  0.000000\n",
      "year   0.000000  0.000000  0.000000  0.0000  0.000000  0.105637\n",
      "zero   0.507059  0.000000  0.000000  0.0000  0.000000  0.000000\n",
      "\n",
      "[392 rows x 6 columns]\n",
      "\n",
      "Query term matrix:\n",
      "    1  10%  12%  175  18%  2  20  2019  2020  24%  ...  viewer  web  weight  \\\n",
      "q1  0    0    0    0    0  0   0     0     0    0  ...       0    0       0   \n",
      "q2  0    0    0    0    0  0   0     0     0    0  ...       0    0       0   \n",
      "q3  0    0    0    0    0  0   0     0     0    0  ...       0    0       0   \n",
      "q4  0    0    0    0    0  0   0     0     0    0  ...       0    0       0   \n",
      "q5  0    0    0    0    0  0   0     0     0    0  ...       0    0       0   \n",
      "\n",
      "    well  within  word  world  x  year  zero  \n",
      "q1     0       0     0      0  0     0     0  \n",
      "q2     0       0     0      0  0     0     0  \n",
      "q3     0       0     0      0  0     0     0  \n",
      "q4     0       0     0      0  0     0     0  \n",
      "q5     0       0     0      0  0     0     0  \n",
      "\n",
      "[5 rows x 392 columns]\n",
      "\n",
      "=== Ranked Documents ===\n",
      "\n",
      "q1:\n",
      "  D1: 0.0000\n",
      "  D2: 0.0000\n",
      "  D3: 0.0000\n",
      "  D4: 0.0000\n",
      "  D5: 0.0000\n",
      "  D6: 0.0000\n",
      "\n",
      "q2:\n",
      "  D1: 0.0000\n",
      "  D2: 0.0000\n",
      "  D3: 0.0000\n",
      "  D4: 0.0000\n",
      "  D5: 0.0000\n",
      "  D6: 0.0000\n",
      "\n",
      "q3:\n",
      "  D1: 0.0000\n",
      "  D2: 0.0000\n",
      "  D3: 0.0000\n",
      "  D4: 0.0000\n",
      "  D5: 0.0000\n",
      "  D6: 0.0000\n",
      "\n",
      "q4:\n",
      "  D1: 0.0000\n",
      "  D2: 0.0000\n",
      "  D3: 0.0000\n",
      "  D4: 0.0000\n",
      "  D5: 0.0000\n",
      "  D6: 0.0000\n",
      "\n",
      "q5:\n",
      "  D6: 0.9970\n",
      "  D3: 0.9863\n",
      "  D2: 0.7828\n",
      "  D4: 0.7087\n",
      "  D5: 0.6007\n",
      "  D1: 0.4152\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1Ô∏è‚É£ Read the inverted file\n",
    "# Format expected: term \\t doc \\t freq \\t tfidf\n",
    "# Example line: 10%    D2    2    0.281699\n",
    "# --------------------------------------------------\n",
    "file_path = \"results/inverted_index_weighted.txt\"\n",
    "\n",
    "# Read with tab or space separators\n",
    "df = pd.read_csv(file_path, sep=r\"\\s+\", header=None, names=[\"term\", \"doc\", \"freq\", \"tfidf\"])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2Ô∏è‚É£ Build TF‚ÄìIDF matrix W (terms √ó documents)\n",
    "# --------------------------------------------------\n",
    "# Get sorted unique terms and docs\n",
    "terms = sorted(df[\"term\"].unique())\n",
    "docs = sorted(df[\"doc\"].unique())\n",
    "\n",
    "# Create empty matrix\n",
    "W = pd.DataFrame(0.0, index=terms, columns=docs)\n",
    "\n",
    "# Fill in TF-IDF values\n",
    "for _, row in df.iterrows():\n",
    "    W.loc[row[\"term\"], row[\"doc\"]] = row[\"tfidf\"]\n",
    "\n",
    "print(\"TF‚ÄìIDF Matrix W:\")\n",
    "print(W)\n",
    "\n",
    "# Convert to numpy array\n",
    "W_matrix = W.to_numpy()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3Ô∏è‚É£ Apply SVD (Singular Value Decomposition)\n",
    "# --------------------------------------------------\n",
    "U, S, VT = np.linalg.svd(W_matrix, full_matrices=False)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4Ô∏è‚É£ Reduce to K=3 dimensions\n",
    "# --------------------------------------------------\n",
    "K = 3\n",
    "U_k = U[:, :K]\n",
    "S_k = np.diag(S[:K])\n",
    "VT_k = VT[:K, :]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5Ô∏è‚É£ Represent queries as binary term vectors\n",
    "# Example: suppose we have two example queries\n",
    "# --------------------------------------------------\n",
    "# q1: large language models for information retrieval and ranking\n",
    "# q2: LLM for information retrieval and Ranking\n",
    "# q3: query Reformulation in information retrieval\n",
    "# q4: ranking Documents\n",
    "# q5: Optimizing recommendation systems with LLMs by leveraging item metadata\n",
    "queries = {\n",
    "    \"q1\": [\"large\", \"language\", \"models\", \"information\", \"retrieval\", \"ranking\"],\n",
    "    \"q2\": [\"LLM\", \"information\", \"retrieval\", \"Ranking\"],\n",
    "    \"q3\": [\"query\", \"Reformulation\", \"information\", \"retrieval\"],\n",
    "    \"q4\": [\"ranking\", \"Documents\"],\n",
    "    \"q5\": [\"Optimizing\", \"recommendation\", \"systems\", \"LLMs\", \"leveraging\", \"item\", \"metadata\"],\n",
    "}\n",
    "\n",
    "Q = pd.DataFrame(0, index=queries.keys(), columns=terms)\n",
    "for q, q_terms in queries.items():\n",
    "    for t in q_terms:\n",
    "        if t in Q.columns:\n",
    "            Q.loc[q, t] = 1\n",
    "\n",
    "print(\"\\nQuery term matrix:\")\n",
    "print(Q)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6Ô∏è‚É£ Project queries into latent semantic space\n",
    "# Formula: q' = q * U_k * S_k^-1\n",
    "# --------------------------------------------------\n",
    "Q_matrix = Q.to_numpy()\n",
    "S_inv = np.linalg.inv(S_k)\n",
    "Q_latent = np.dot(np.dot(Q_matrix, U_k), S_inv)\n",
    "\n",
    "# Project documents into the same space\n",
    "D_latent = np.dot(S_k, VT_k).T  # shape: docs √ó K\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7Ô∏è‚É£ Compute cosine similarity between each query and document\n",
    "# --------------------------------------------------\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "similarities = {}\n",
    "for i, q_name in enumerate(Q.index):\n",
    "    sims = {}\n",
    "    for j, doc_name in enumerate(docs):\n",
    "        sims[doc_name] = cosine_similarity(Q_latent[i], D_latent[j])\n",
    "    # Sort in decreasing order\n",
    "    sims_sorted = dict(sorted(sims.items(), key=lambda x: x[1], reverse=True))\n",
    "    similarities[q_name] = sims_sorted\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 8Ô∏è‚É£ Display ranked documents for each query\n",
    "# --------------------------------------------------\n",
    "print(\"\\n=== Ranked Documents ===\")\n",
    "for q, sims in similarities.items():\n",
    "    print(f\"\\n{q}:\")\n",
    "    for doc, score in sims.items():\n",
    "        print(f\"  {doc}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
