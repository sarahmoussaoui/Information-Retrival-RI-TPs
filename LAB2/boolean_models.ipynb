{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0706832",
   "metadata": {},
   "source": [
    "# Task 1 – Boolean Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a998963",
   "metadata": {},
   "source": [
    "## Classic boolean model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d600bc2",
   "metadata": {},
   "source": [
    "Each term is binary (present or not).\n",
    "\n",
    "Retrieve only documents that exactly satisfy the Boolean expression.\n",
    "\n",
    "Operators: AND, OR, NOT.\n",
    "\n",
    "Example query: q = (query AND reformulation) OR (Language AND model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f2740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classic Boolean Model Results:\n",
      "Query: (queri AND reformul) OR (languag AND model)\n",
      "Retrieved documents: ['D1.txt', 'D4.txt']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ========== 1. Preprocessing (same as Lab 1) ==========\n",
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    # Same regex as used before\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stops]\n",
    "    return tokens\n",
    "\n",
    "# ========== 2. Load Inverted Index ==========\n",
    "# Expected format:\n",
    "# term  doc_id  \n",
    "def load_inverted_index(filepath):\n",
    "    inverted = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            term, doc_id = parts[0], parts[1]\n",
    "            if term not in inverted:  # inverted.setdefault(term, set()).add(doc_id)\n",
    "                inverted[term] = set()\n",
    "            inverted[term].add(doc_id)\n",
    "    return inverted\n",
    "\n",
    "\n",
    "# ========== 3. Parse and Evaluate Boolean Query ==========\n",
    "def evaluate_boolean_query(query, inverted_index, all_docs):\n",
    "    # Preprocess and keep original\n",
    "    original_query = query\n",
    "    tokens = preprocess(query)\n",
    "    expression = original_query.lower()\n",
    "\n",
    "    # Replace **stemmed tokens** in the expression\n",
    "    for token in tokens:\n",
    "        docs = inverted_index.get(token, set())\n",
    "        expression = re.sub(rf'\\b{token}\\b', f\"set({list(docs)})\", expression)\n",
    "\n",
    "    # Replace logical operators with Python equivalents\n",
    "    expression = expression.replace(\" AND \", \" & \")\n",
    "    expression = expression.replace(\" OR \", \" | \")\n",
    "    expression = expression.replace(\" NOT \", f\" all_docs - \")\n",
    "\n",
    "    # Evaluate expression safely\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": None}, {\"all_docs\": all_docs, \"set\": set}) \n",
    "    except Exception as e:\n",
    "        print(\"Error in query:\", e)\n",
    "        return set()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ========== 4. Example Run ==========\n",
    "if __name__ == \"__main__\":\n",
    "    inverted_index = load_inverted_index(\"results/inverted_index.txt\")\n",
    "    all_docs = {f\"D{i}.txt\" for i in range(1, 7)}  # D1–D6\n",
    "\n",
    "    query = \"(query AND reformulation) OR (language AND model)\"\n",
    "    relevant_docs = evaluate_boolean_query(query, inverted_index, all_docs)\n",
    "\n",
    "    print(\"\\nClassic Boolean Model Results:\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Retrieved documents:\", sorted(relevant_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec43351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classic Boolean Model Results:\n",
      "Query: (query AND reformulation) AND (language AND model)\n",
      "Retrieved documents: ['D1.txt', 'D4.txt']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ---------- 1. Preprocessing ----------\n",
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stops]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# ---------- 2. Load Inverted Index ----------\n",
    "def load_inverted_index(filepath):\n",
    "    inverted = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                term, doc_id = parts[0], parts[1]\n",
    "                inverted.setdefault(term, set()).add(doc_id)\n",
    "    return inverted\n",
    "\n",
    "\n",
    "# ---------- 3. Evaluate Boolean Query ----------\n",
    "def evaluate_boolean_query(query, inverted_index, all_docs):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "\n",
    "    # Extract all candidate words (ignoring AND/OR/NOT and parentheses)\n",
    "    raw_tokens = re.findall(r'\\b[a-zA-Z]+\\b', query)\n",
    "    unique_tokens = set(raw_tokens) - {\"AND\", \"OR\", \"NOT\"}\n",
    "\n",
    "    # Start with the original expression\n",
    "    expression = query\n",
    "\n",
    "    # For each token, find its stemmed version and replace it\n",
    "    for token in unique_tokens:\n",
    "        if token.lower() in stops:\n",
    "            continue\n",
    "        stemmed = stemmer.stem(token.lower())\n",
    "        docs = inverted_index.get(stemmed, set())\n",
    "        expression = re.sub(rf'\\b{token}\\b', f\"set({list(docs)})\", expression, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace logical operators with Python equivalents\n",
    "    expression = re.sub(r\"\\bAND\\b\", \"&\", expression, flags=re.IGNORECASE)\n",
    "    expression = re.sub(r\"\\bOR\\b\", \"|\", expression, flags=re.IGNORECASE)\n",
    "    expression = re.sub(r\"\\bNOT\\b\", \"all_docs -\", expression, flags=re.IGNORECASE)\n",
    "\n",
    "    # Evaluate expression safely\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": None}, {\"all_docs\": all_docs, \"set\": set})\n",
    "    except Exception as e:\n",
    "        print(\"Error in query:\", e)\n",
    "        print(\"Expression after replacements:\", expression)\n",
    "        return set()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------- 4. Example Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    inverted_index = load_inverted_index(\"results/inverted_index.txt\")\n",
    "    all_docs = {f\"D{i}.txt\" for i in range(1, 7)}\n",
    "\n",
    "    query = \"(query AND reformulation) OR (language AND model)\"\n",
    "    relevant_docs = evaluate_boolean_query(query, inverted_index, all_docs)\n",
    "\n",
    "    print(\"\\nClassic Boolean Model Results:\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Retrieved documents:\", sorted(relevant_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e7c1e",
   "metadata": {},
   "source": [
    "## Fuzzy boolean model\n",
    "Each term gets a degree of membership between 0 and 1 (based on TF or TF-IDF).\n",
    "\n",
    "Logical operators are softened using fuzzy logic:\n",
    "\n",
    "AND → min()\n",
    "\n",
    "OR → max()\n",
    "\n",
    "NOT → 1 − value\n",
    "\n",
    "You then compute a degree of relevance for each document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d99857",
   "metadata": {},
   "source": [
    "## Extended Boolean Model\n",
    "\n",
    "- **Combines** the Boolean and Vector models.  \n",
    "- **Allows partial matching** using *p-norms*:\n",
    "\n",
    "#### For AND:\n",
    "$$\n",
    "S_{AND}(d, q) = \\left( \\sum_{i} w_{di}^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "#### For OR:\n",
    "$$\n",
    "S_{OR}(d, q) = \\left( \\sum_{i} (1 - w_{di})^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "*(depending on the specific formulation used in your lecture notes)*  \n",
    "\n",
    "➡️ You’ll **rank documents** by their score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bf511",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe35140",
   "metadata": {},
   "source": [
    "Test Query\n",
    "q = (query AND reformulation) OR (Language AND model)  \n",
    "- Parentheses define precedence\n",
    "- Expected Steps\n",
    "1. Preprocess the query using the same pipeline as for documents (tokenization, stop word\n",
    "removal, and stemming).\n",
    "1. Parse the Boolean expression into logical operations.\n",
    "2. For the Classic Boolean Model: retrieve only the documents that strictly satisfy the\n",
    "Boolean condition.\n",
    "1. For the Fuzzy and Extended Boolean Models:\n",
    "o Compute partial degrees of relevance for each document according to the model’s\n",
    "equations given in lecture notes.\n",
    "o Rank documents by their computed degree of match with the query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff022e",
   "metadata": {},
   "source": [
    "### Preprocess the query using the same pipeline as for documents (tokenization, stop word removal, and stemming).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf68d53",
   "metadata": {},
   "source": [
    "### Parse the Boolean expression into logical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f446e",
   "metadata": {},
   "source": [
    "### For the Classic Boolean Model: retrieve only the documents that strictly satisfy the Boolean condition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b03529",
   "metadata": {},
   "source": [
    "### For the Fuzzy and Extended Boolean Models:\n",
    "- Compute partial degrees of relevance for each document according to the model’s equations given in lecture notes.\n",
    "- Rank documents by their computed degree of match with the query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
