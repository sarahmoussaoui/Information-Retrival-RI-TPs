{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0706832",
   "metadata": {},
   "source": [
    "# Task 1 – Boolean Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a998963",
   "metadata": {},
   "source": [
    "## Classic boolean model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d600bc2",
   "metadata": {},
   "source": [
    "Each term is binary (present or not).\n",
    "\n",
    "Retrieve only documents that exactly satisfy the Boolean expression.\n",
    "\n",
    "Operators: AND, OR, NOT.\n",
    "\n",
    "Example query: q = (query AND reformulation) OR (Language AND model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec43351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classic Boolean Model Results:\n",
      "Query: (query AND reformulation) OR (language AND model)\n",
      "Retrieved documents: ['D1.txt', 'D2.txt', 'D3.txt', 'D4.txt', 'D5.txt', 'D6.txt']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ---------- 1. Preprocessing ----------\n",
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stops]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# ---------- 2. Load Inverted Index ----------\n",
    "def load_inverted_index(filepath):\n",
    "    inverted = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                term, doc_id = parts[0], parts[1]\n",
    "                inverted.setdefault(term, set()).add(doc_id)\n",
    "    return inverted\n",
    "\n",
    "\n",
    "# ---------- 3. Evaluate Boolean Query ----------\n",
    "def evaluate_boolean_query(query, inverted_index, all_docs):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "\n",
    "    # Extract all candidate words (ignoring AND/OR/NOT and parentheses)\n",
    "    raw_tokens = re.findall(r'\\b[a-zA-Z]+\\b', query)\n",
    "    unique_tokens = set(raw_tokens) - {\"AND\", \"OR\", \"NOT\"}\n",
    "\n",
    "    # Start with the original expression\n",
    "    expression = query\n",
    "\n",
    "    # For each token, find its stemmed version and replace it\n",
    "    for token in unique_tokens:\n",
    "        if token.lower() in stops:\n",
    "            continue\n",
    "        stemmed = stemmer.stem(token.lower())\n",
    "        docs = inverted_index.get(stemmed, set())\n",
    "        expression = re.sub(rf'\\b{token}\\b', f\"set({list(docs)})\", expression, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace logical operators with Python equivalents\n",
    "    expression = re.sub(r\"\\bAND\\b\", \"&\", expression, flags=re.IGNORECASE)\n",
    "    expression = re.sub(r\"\\bOR\\b\", \"|\", expression, flags=re.IGNORECASE)\n",
    "    expression = re.sub(r\"\\bNOT\\b\", \"all_docs -\", expression, flags=re.IGNORECASE)\n",
    "\n",
    "    # Evaluate expression safely\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": None}, {\"all_docs\": all_docs, \"set\": set})\n",
    "    except Exception as e:\n",
    "        print(\"Error in query:\", e)\n",
    "        print(\"Expression after replacements:\", expression)\n",
    "        return set()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------- 4. Example Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    inverted_index = load_inverted_index(\"results/inverted_index.txt\")\n",
    "    all_docs = {f\"D{i}.txt\" for i in range(1, 7)}\n",
    "\n",
    "    query = \"(query AND reformulation) OR (language AND model)\"\n",
    "    relevant_docs = evaluate_boolean_query(query, inverted_index, all_docs)\n",
    "\n",
    "    print(\"\\nClassic Boolean Model Results:\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Retrieved documents:\", sorted(relevant_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e7c1e",
   "metadata": {},
   "source": [
    "## Fuzzy boolean model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76864765",
   "metadata": {},
   "source": [
    "Each term gets a degree of membership between 0 and 1 (based on TF or TF-IDF).\n",
    "\n",
    "Logical operators are softened using fuzzy logic:\n",
    "\n",
    "AND → min()\n",
    "\n",
    "OR → max()\n",
    "\n",
    "NOT → 1 − value\n",
    "\n",
    "You then compute a degree of relevance for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "971fd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluating D4.txt: invalid syntax (<string>, line 1)\n",
      "Error evaluating D6.txt: invalid syntax (<string>, line 1)\n",
      "Error evaluating D3.txt: invalid syntax (<string>, line 1)\n",
      "Error evaluating D5.txt: invalid syntax (<string>, line 1)\n",
      "Error evaluating D2.txt: invalid syntax (<string>, line 1)\n",
      "Error evaluating D1.txt: invalid syntax (<string>, line 1)\n",
      "\n",
      "Fuzzy Boolean Model Results:\n",
      "D4.txt: 0.000\n",
      "D6.txt: 0.000\n",
      "D3.txt: 0.000\n",
      "D5.txt: 0.000\n",
      "D2.txt: 0.000\n",
      "D1.txt: 0.000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ---------- 1. Preprocessing ----------\n",
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stops]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# ---------- 2. Load Fuzzy Index ----------\n",
    "# Expected format: <term> <doc_id> <tf> <tfidf>\n",
    "def load_fuzzy_index(filepath):\n",
    "    fuzzy = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            term, doc_id, weight = parts[0], parts[1], float(parts[3])\n",
    "            fuzzy.setdefault(term, {})[doc_id] = weight\n",
    "    return fuzzy\n",
    "\n",
    "\n",
    "# ---------- 3. Fuzzy Operators ----------\n",
    "def fuzzy_and(a, b):\n",
    "    return min(a, b) \n",
    "\n",
    "def fuzzy_or(a, b):\n",
    "    return max(a, b)  \n",
    "\n",
    "def fuzzy_not(a):\n",
    "    return 1 - a\n",
    "\n",
    "\n",
    "# ---------- 4. Evaluate Fuzzy Boolean Query ----------\n",
    "def evaluate_fuzzy_query(query, fuzzy_index, all_docs):\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = set(stopwords.words('english'))\n",
    "\n",
    "    raw_tokens = re.findall(r'\\b[a-zA-Z]+\\b', query)\n",
    "    unique_tokens = set(raw_tokens) - {\"AND\", \"OR\", \"NOT\"} \n",
    "\n",
    "    # Initialize document scores\n",
    "    doc_scores = {doc: 0.0 for doc in all_docs}\n",
    "\n",
    "    # For each document, evaluate query with fuzzy logic : each document’s membership degree depends on its own term weights.\n",
    "    for doc in all_docs:\n",
    "        expression = query\n",
    "\n",
    "        for token in unique_tokens:\n",
    "            if token.lower() in stops:\n",
    "                continue\n",
    "            stemmed = stemmer.stem(token.lower())\n",
    "            w = fuzzy_index.get(stemmed, {}).get(doc, 0.0)\n",
    "            expression = re.sub(rf'\\b{token}\\b', str(w), expression, flags=re.IGNORECASE)\n",
    "            # (query AND reformulation) OR (language AND model)\n",
    "            # → (0.36 AND 0.42) OR (0.10 AND 0.08)\n",
    "\n",
    "\n",
    "        # 2️⃣ Convert the Boolean operators to Python functions\n",
    "        # Handle NOT first\n",
    "        expression = re.sub(r\"\\bNOT\\s+([\\d.]+)\", r\"(1-\\1)\", expression, flags=re.IGNORECASE)\n",
    "        # Handle AND\n",
    "        while re.search(r\"([\\d.]+)\\s+AND\\s+([\\d.]+)\", expression):\n",
    "            expression = re.sub(r\"([\\d.]+)\\s+AND\\s+([\\d.]+)\", r\"min(\\1, \\2)\", expression, flags=re.IGNORECASE)\n",
    "        # Handle OR\n",
    "        while re.search(r\"([\\d.]+)\\s+OR\\s+([\\d.]+)\", expression):\n",
    "            expression = re.sub(r\"([\\d.]+)\\s+OR\\s+([\\d.]+)\", r\"max(\\1, \\2)\", expression, flags=re.IGNORECASE)\n",
    "\n",
    "        try:\n",
    "            val = eval(expression, {\"__builtins__\": None}, {\"min\": min, \"max\": max, \"float\": float})\n",
    "            doc_scores[doc] = val if isinstance(val, float) else 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {doc}: {e}\")\n",
    "\n",
    "\n",
    "    # Sort by decreasing score\n",
    "    ranked = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return ranked\n",
    "\n",
    "\n",
    "# ---------- 5. Example Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Example fuzzy index structure:\n",
    "    #     fuzzy_index = {\n",
    "    #     \"queri\": {\"D1.txt\": 0.36, \"D2.txt\": 0.20},\n",
    "    #     \"reformul\": {\"D1.txt\": 0.42},\n",
    "    #     ...\n",
    "    #      }\n",
    "\n",
    "    fuzzy_index = load_fuzzy_index(\"results/inverted_index_weighted.txt\")  # file with TF-IDF weights\n",
    "    all_docs = {f\"D{i}.txt\" for i in range(1, 7)}\n",
    "\n",
    "    query = \"(query AND reformulation) OR (language AND model)\"\n",
    "    ranked_docs = evaluate_fuzzy_query(query, fuzzy_index, all_docs)\n",
    "\n",
    "    print(\"\\nFuzzy Boolean Model Results:\")\n",
    "    for doc, score in ranked_docs:\n",
    "        print(f\"{doc}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd3da3",
   "metadata": {},
   "source": [
    "## Extended Boolean Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d99857",
   "metadata": {},
   "source": [
    "- **Combines** the Boolean and Vector models.  \n",
    "- **Allows partial matching** using *p-norms*:\n",
    "\n",
    "#### For AND:\n",
    "$$\n",
    "S_{AND}(d, q) = \\left( \\sum_{i} w_{di}^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "#### For OR:\n",
    "$$\n",
    "S_{OR}(d, q) = \\left( \\sum_{i} (1 - w_{di})^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "\n",
    "➡️ You’ll **rank documents** by their score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bf511",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f542d48",
   "metadata": {},
   "source": [
    "## Vector Space Model (VSM) for Information Retrieval\n",
    "\n",
    "In this notebook, we implement the Vector Space Model using TF–IDF weighted document vectors and compute similarity between queries and documents using three measures:\n",
    "\n",
    "- **Inner Product Similarity**\n",
    "- **Cosine Similarity**\n",
    "- **Jaccard Similarity**\n",
    "\n",
    "We test the model on the following queries:\n",
    "\n",
    "1. `q1`: large language models for information retrieval and ranking  \n",
    "2. `q2`: LLM for information retrieval and Ranking  \n",
    "3. `q3`: query Reformulation in information retrieval  \n",
    "4. `q4`: ranking Documents  \n",
    "5. `q5`: Optimizing recommendation systems with LLMs by leveraging item metadata\n",
    "\n",
    "6. **Load the Document–Term and Inverted Index files**  \n",
    "   - Use the files generated in Lab 1 to access the TF–IDF weights of terms in each document.\n",
    "\n",
    "7. **Preprocess each query**  \n",
    "   - Tokenize the query text.  \n",
    "   - Remove stop words.  \n",
    "   - Apply stemming (e.g., Porter Stemmer).\n",
    "\n",
    "8. **For each similarity measure (Inner Product, Cosine, Jaccard):**  \n",
    "   - Compute the similarity score between the query and every document.  \n",
    "   - Use a **binary weighting scheme** for queries:  \n",
    "     - Weight = 1 if the term appears in the query.  \n",
    "     - Weight = 0 if the term does not appear.  \n",
    "   - Rank the documents in **descending order of similarity**.  \n",
    "   - Display the ranked documents for each query.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
