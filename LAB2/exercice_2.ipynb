{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ce9705",
   "metadata": {},
   "source": [
    "# Vector Space Model (VSM)\n",
    "## Using TF-IDF weights from Boolean Model (exercice_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab83c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load data from exercice_1 output files\n",
    "output_dir = \"exercice_1\"\n",
    "\n",
    "# Initialize preprocessing tools (needed for loading)\n",
    "tokenizer = RegexpTokenizer(\n",
    "    r'(?:[A-Za-z]\\.)+|[A-Za-z]+[\\-@]\\d+(?:\\.\\d+)?|\\d+(?:[\\.\\,\\-]\\d+)*%?|[A-Za-z]+'\n",
    ")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61668ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Load documents from Collection folder\n",
    "collection_path = \"../Collection\"\n",
    "documents = {}\n",
    "for filename in os.listdir(collection_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        doc_id = filename.split(\".\")[0]\n",
    "        with open(os.path.join(collection_path, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            documents[doc_id] = f.read()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e364a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 392 terms\n",
      "Number of documents: 6\n"
     ]
    }
   ],
   "source": [
    "# Load TF-IDF weights from exercice_1 output\n",
    "tfidf_file = os.path.join(output_dir, \"TFIDF_Weights.txt\")\n",
    "tfidf_weights = defaultdict(dict)\n",
    "doc_terms = defaultdict(list)\n",
    "\n",
    "with open(tfidf_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 3:\n",
    "            doc_id, term, weight = parts[0], parts[1], float(parts[2])\n",
    "            tfidf_weights[doc_id][term] = weight\n",
    "            if term not in doc_terms[doc_id]:\n",
    "                doc_terms[doc_id].append(term)\n",
    "\n",
    "# Convert to regular dicts\n",
    "tfidf_weights = dict(tfidf_weights)\n",
    "doc_terms = dict(doc_terms)\n",
    "\n",
    "# Compute IDF from document terms\n",
    "def compute_idf(doc_terms):\n",
    "    N = len(doc_terms)\n",
    "    df = {}\n",
    "    for terms in doc_terms.values():\n",
    "        for t in set(terms):\n",
    "            df[t] = df.get(t, 0) + 1\n",
    "    return {t: math.log10((N / df[t]) + 1) for t in df}\n",
    "\n",
    "idf = compute_idf(doc_terms)\n",
    "vocab = set(idf.keys())\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab)} terms\")\n",
    "print(f\"Number of documents: {len(doc_terms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd50fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    tokens = [porter.stem(t) for t in tokens if t not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c333113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query vector creation (weighted by IDF)\n",
    "def create_query_vector(query_text, vocab, idf):\n",
    "    terms = preprocess_text(query_text)\n",
    "    unique = set(terms)\n",
    "    query_vec = {t: idf.get(t, 0) for t in unique if t in vocab}\n",
    "    return query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9deba673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity measures\n",
    "def inner_product(vd, vq):\n",
    "    return sum(vd[t] * vq[t] for t in set(vd) & set(vq))\n",
    "\n",
    "def cosine_similarity(vd, vq):\n",
    "    num = inner_product(vd, vq)\n",
    "    den = math.sqrt(sum(w**2 for w in vd.values()) * sum(w**2 for w in vq.values()))\n",
    "    return 0.0 if den == 0 else num / den\n",
    "\n",
    "def dice_similarity(vd, vq):\n",
    "    num = 2 * inner_product(vd, vq)\n",
    "    den = sum(w**2 for w in vd.values()) + sum(w**2 for w in vq.values())\n",
    "    return 0.0 if den == 0 else num / den\n",
    "\n",
    "def jaccard_similarity(vd, vq):\n",
    "    num = inner_product(vd, vq)\n",
    "    den = sum(w**2 for w in vd.values()) + sum(w**2 for w in vq.values()) - num\n",
    "    return 0.0 if den == 0 else num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a271cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document ranking function\n",
    "def rank_documents(query_vec, doc_vectors, func):\n",
    "    scores = {d: func(v, query_vec) for d, v in doc_vectors.items()}\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e5cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define queries\n",
    "queries = {\n",
    "    \"q1\": \"large language models for information retrieval and ranking\",\n",
    "    \"q2\": \"LLM for information retrieval and Ranking\",\n",
    "    \"q3\": \"query Reformulation in information retrieval\",\n",
    "    \"q4\": \"ranking Documents\",\n",
    "    \"q5\": \"Optimizing recommendation systems with LLMs by leveraging item metadata\"\n",
    "}\n",
    "\n",
    "# Define similarity measures\n",
    "measures = {\n",
    "    \"Inner_Product\": inner_product,\n",
    "    \"Cosine\": cosine_similarity,\n",
    "    \"Dice\": dice_similarity,\n",
    "    \"Jaccard\": jaccard_similarity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d112817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ” q1: large language models for information retrieval and ranking\n",
      "Query terms (stemmed): ['inform', 'languag', 'larg', 'model', 'rank', 'retriev']\n",
      "======================================================================\n",
      "          Inner_Product    Cosine      Dice   Jaccard\n",
      "Document                                             \n",
      "D2             0.437999  0.217365  0.187574  0.103493\n",
      "D4             0.276144  0.223399  0.222888  0.125421\n",
      "D1             0.271529  0.137537  0.119902  0.063774\n",
      "D5             0.169800  0.080608  0.067969  0.035180\n",
      "D3             0.133385  0.092312  0.090047  0.047146\n",
      "D6             0.065353  0.041717  0.039853  0.020332\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ” q2: LLM for information retrieval and Ranking\n",
      "Query terms (stemmed): ['inform', 'llm', 'rank', 'retriev']\n",
      "======================================================================\n",
      "          Inner_Product    Cosine      Dice   Jaccard\n",
      "Document                                             \n",
      "D2             0.479549  0.255711  0.212400  0.118818\n",
      "D4             0.275143  0.239169  0.236859  0.134339\n",
      "D1             0.217344  0.118291  0.099366  0.052281\n",
      "D5             0.196299  0.100129  0.081085  0.042255\n",
      "D6             0.093175  0.063907  0.059631  0.030732\n",
      "D3             0.078451  0.058338  0.055878  0.028742\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ” q3: query Reformulation in information retrieval\n",
      "Query terms (stemmed): ['inform', 'queri', 'reformul', 'retriev']\n",
      "======================================================================\n",
      "          Inner_Product    Cosine      Dice   Jaccard\n",
      "Document                                             \n",
      "D4             0.555839  0.473536  0.470179  0.307343\n",
      "D1             0.457548  0.244061  0.207237  0.115596\n",
      "D5             0.105454  0.052718  0.043193  0.022073\n",
      "D2             0.026264  0.013726  0.011528  0.005797\n",
      "D3             0.019897  0.014501  0.013967  0.007033\n",
      "D6             0.019897  0.013375  0.012568  0.006324\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ” q4: ranking Documents\n",
      "Query terms (stemmed): ['document', 'rank']\n",
      "======================================================================\n",
      "          Inner_Product    Cosine      Dice   Jaccard\n",
      "Document                                             \n",
      "D2             0.438302  0.304328  0.213541  0.119533\n",
      "D1             0.117574  0.083323  0.059318  0.030566\n",
      "D5             0.038170  0.025352  0.017227  0.008688\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ” q5: Optimizing recommendation systems with LLMs by leveraging item metadata\n",
      "Query terms (stemmed): ['item', 'leverag', 'llm', 'optim', 'recommend', 'system']\n",
      "======================================================================\n",
      "          Inner_Product    Cosine      Dice   Jaccard\n",
      "Document                                             \n",
      "D3             0.466751  0.236969  0.236096  0.133849\n",
      "D6             0.254499  0.119175  0.119174  0.063362\n",
      "D4             0.169050  0.100327  0.097457  0.051225\n",
      "D5             0.155278  0.054076  0.051865  0.026623\n",
      "D2             0.117109  0.042634  0.041370  0.021122\n",
      "D1             0.045327  0.016843  0.016421  0.008278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run all queries and display results as DataFrames\n",
    "for qn, qt in queries.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ðŸ” {qn}: {qt}\")\n",
    "    \n",
    "    # Create query vector\n",
    "    qvec = create_query_vector(qt, vocab, idf)\n",
    "    print(f\"Query terms (stemmed): {sorted(qvec.keys())}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Collect scores for all similarity measures\n",
    "    doc_scores = {}\n",
    "    \n",
    "    for measure_name, measure_func in measures.items():\n",
    "        ranked = rank_documents(qvec, tfidf_weights, measure_func)\n",
    "        for doc, score in ranked:\n",
    "            if doc not in doc_scores:\n",
    "                doc_scores[doc] = {}\n",
    "            doc_scores[doc][measure_name] = score\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame.from_dict(doc_scores, orient='index')\n",
    "    df.index.name = 'Document'\n",
    "    \n",
    "    # Fill missing values with 0\n",
    "    df = df.fillna(0.0)\n",
    "    \n",
    "    # Sort by Inner Product (primary metric)\n",
    "    df = df.sort_values(by='Inner_Product', ascending=False)\n",
    "    \n",
    "    # Filter out documents with all zero scores\n",
    "    df = df[(df > 0).any(axis=1)]\n",
    "    \n",
    "    # Display the table\n",
    "    print(df.to_string())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
